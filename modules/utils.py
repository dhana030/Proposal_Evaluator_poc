import pandas as pd
import fitz
import os
import requests

# Define chunking parameters
CHUNK_SIZE = 512
CHUNK_OVERLAP = 100
EMBEDDING_DIM = 768 # Jina-embeddings-v4

def recursive_chunking(text: str, chunk_size: int = CHUNK_SIZE, chunk_overlap: int = CHUNK_OVERLAP):
    """Simple, recursive text chunking with overlap."""
    chunks = []
    start = 0
    
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        
        # Move start point for the next chunk, accounting for overlap
        start += chunk_size - chunk_overlap
        
        if end >= len(text):
            break
            
    return chunks

def extract_text_from_pdf_page(pdf_path: str, page_number: int) -> str:
    """Extracts text from a single page of a PDF file using PyMuPDF (fitz)."""
    try:
        with fitz.open(pdf_path) as doc:
            if page_number < 0 or page_number >= len(doc):
                print(f"❌ Error: Page number {page_number} is out of bounds. PDF has {len(doc)} pages.")
                return None
            page = doc[page_number]
            text = page.get_text("text")
            return text.strip()
    except Exception as e:
        print(f"❌ Error extracting text from {pdf_path}: {e}")
        return None

def get_jina_embeddings(texts, model: str = "jina-embeddings-v2-base-en"):
    """Call Jina Embeddings API via HTTP and return list of embeddings."""
    api_key = os.getenv("JINA_API_KEY")
    if not api_key:
        raise RuntimeError("JINA_API_KEY is not set in environment.")
    url = "https://api.jina.ai/v1/embeddings"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {"input": texts, "model": model}
    resp = requests.post(url, headers=headers, json=payload, timeout=120)
    resp.raise_for_status()
    data = resp.json()
    return [item["embedding"] for item in data.get("data", [])]

def extract_criteria_from_rubric(markdown_table: str) -> pd.DataFrame:
    """
    Parses the markdown table generated by Kimi into a DataFrame.
    This DataFrame is used to drive the evaluation loop.
    """
    try:
        # Robust parsing logic for markdown tables that may contain blank cells
        lines = [ln for ln in markdown_table.strip().split('\n') if ln.strip()]
        if len(lines) < 3:
            raise ValueError("Table is too short to be a markdown table.")

        # Find header and separator lines
        header_idx = next((i for i, ln in enumerate(lines) if ln.strip().startswith('|')), None)
        sep_idx = None
        if header_idx is not None:
            for j in range(header_idx + 1, min(header_idx + 4, len(lines))):
                if set(lines[j].replace('|', '').strip()) <= set('-: '):
                    sep_idx = j
                    break
        if header_idx is None or sep_idx is None:
            raise ValueError("Markdown table header/separator not found")

        # Parse header (keep empty columns)
        raw_header_cells = [c.strip() for c in lines[header_idx].split('|')]
        # remove table border empties (first and last are empty because of leading/trailing pipes)
        columns = raw_header_cells[1:-1]

        # Parse rows; keep empty cells and pad/truncate to match columns
        data = []
        for ln in lines[sep_idx + 1:]:
            if not ln.strip().startswith('|'):
                # Stop when the table ends
                break
            cells = [c.strip() for c in ln.split('|')][1:-1]
            if len(cells) < len(columns):
                cells = cells + [''] * (len(columns) - len(cells))
            elif len(cells) > len(columns):
                cells = cells[:len(columns)]
            data.append(cells)

        if not data:
            return pd.DataFrame()

        df = pd.DataFrame(data, columns=columns)

        # Forward-fill Main/Weight columns in case Kimi leaves them blank for subsequent sub-rows
        main_col_candidates = [
            'Main Criterion (with English translation in brackets)',
            'Main Criterion',
        ]
        for col in main_col_candidates:
            if col in df.columns:
                df[col] = df[col].replace('', pd.NA).ffill()
                break

        # Normalize/rename columns used by the evaluation loop
        rename_map = {
            'Main Criterion (with English translation in brackets)': 'Main_Criterion',
            'Main Criterion': 'Main_Criterion',
            'Sub-Criterion (with English translation in brackets)': 'Sub_Criterion',
            'Sub-Criterion': 'Sub_Criterion',
            'Expectation / Evaluation Rubric': 'Rubric',
            'Expectation': 'Rubric',
            'Evaluation Rubric': 'Rubric',
        }
        df = df.rename(columns=rename_map)

        # Keep only necessary columns; do not drop rows just because some fields were blank before ffill
        needed_cols = [c for c in ['Main_Criterion', 'Sub_Criterion', 'Rubric'] if c in df.columns]
        df = df[needed_cols]

        # Drop rows that truly cannot be evaluated (missing sub-criterion or rubric)
        df = df.dropna(subset=[c for c in ['Sub_Criterion', 'Rubric'] if c in df.columns])
        df = df[(df['Sub_Criterion'].astype(str).str.strip() != '') & (df['Rubric'].astype(str).str.strip() != '')]

        return df
    
    except Exception as e:
        print(f"Error parsing Kimi output table: {e}")
        return pd.DataFrame()
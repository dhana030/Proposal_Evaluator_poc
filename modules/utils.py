import pandas as pd
import fitz
import os
import requests

# Define chunking parameters
CHUNK_SIZE = 512
CHUNK_OVERLAP = 100
EMBEDDING_DIM = 768 # Jina-embeddings-v4

def recursive_chunking(text: str, chunk_size: int = CHUNK_SIZE, chunk_overlap: int = CHUNK_OVERLAP):
    """Simple, recursive text chunking with overlap."""
    chunks = []
    start = 0
    
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        
        # Move start point for the next chunk, accounting for overlap
        start += chunk_size - chunk_overlap
        
        if end >= len(text):
            break
            
    return chunks

def extract_text_from_pdf_page(pdf_path: str, page_number: int) -> str:
    """Extracts text from a single page of a PDF file using PyMuPDF (fitz)."""
    try:
        with fitz.open(pdf_path) as doc:
            if page_number < 0 or page_number >= len(doc):
                print(f"❌ Error: Page number {page_number} is out of bounds. PDF has {len(doc)} pages.")
                return None
            page = doc[page_number]
            text = page.get_text("text")
            return text.strip()
    except Exception as e:
        print(f"❌ Error extracting text from {pdf_path}: {e}")
        return None

def get_jina_embeddings(texts, model: str = "jina-embeddings-v2-base-en"):
    """Call Jina Embeddings API via HTTP and return list of embeddings."""
    api_key = os.getenv("JINA_API_KEY")
    if not api_key:
        raise RuntimeError("JINA_API_KEY is not set in environment.")
    url = "https://api.jina.ai/v1/embeddings"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {"input": texts, "model": model}
    resp = requests.post(url, headers=headers, json=payload, timeout=120)
    resp.raise_for_status()
    data = resp.json()
    return [item["embedding"] for item in data.get("data", [])]

def extract_criteria_from_rubric(markdown_table: str) -> pd.DataFrame:
    """
    Parses the markdown table generated by Kimi into a DataFrame.
    This DataFrame is used to drive the evaluation loop.
    """
    try:
        # Simple extraction logic for markdown tables
        lines = markdown_table.strip().split('\n')
        # Find header line (usually the third line in a standard markdown table)
        if len(lines) < 3:
            raise ValueError("Table is too short to be a markdown table.")

        header_line = lines[0]
        # Clean up column names by removing surrounding pipes and excessive spaces
        columns = [col.strip() for col in header_line.split('|') if col.strip()]
        
        data = []
        # Start reading data after the header and separator lines
        for line in lines[2:]: 
            if line.strip().startswith('|') and line.strip().endswith('|'):
                values = [val.strip() for val in line.split('|') if val.strip()]
                if len(values) == len(columns):
                    data.append(values)
        
        df = pd.DataFrame(data, columns=columns)
        # Select and rename the critical columns for the evaluation loop
        df = df.rename(columns={
            'Main Criterion (with English translation in brackets)': 'Main_Criterion',
            'Sub-Criterion (with English translation in brackets)': 'Sub_Criterion',
            'Expectation / Evaluation Rubric': 'Rubric'
        })
        return df[['Main_Criterion', 'Sub_Criterion', 'Rubric']].dropna()
    
    except Exception as e:
        print(f"Error parsing Kimi output table: {e}")
        return pd.DataFrame()